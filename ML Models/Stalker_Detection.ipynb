{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "df = pd.read_csv(\"stalker_detection.csv\")\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df.dropna(inplace=True)\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")  # Fix timestamp issues\n",
        "    df.dropna(subset=[\"timestamp\"], inplace=True)\n",
        "    df.sort_values(by=[\"user_id\", \"timestamp\"], inplace=True)\n",
        "    return df\n",
        "\n",
        "df = preprocess_data(df)\n",
        "\n",
        "df[\"time_diff\"] = df.groupby(\"user_id\")[\"timestamp\"].diff().dt.total_seconds().fillna(0)\n",
        "df[\"distance_diff\"] = df.groupby(\"user_id\").apply(\n",
        "    lambda group: [0] + [geodesic((group.latitude.iloc[i - 1], group.longitude.iloc[i - 1]),\n",
        "                                  (group.latitude.iloc[i], group.longitude.iloc[i])).meters\n",
        "                          for i in range(1, len(group))]\n",
        ").explode().values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[[\"latitude\", \"longitude\", \"time_diff\", \"distance_diff\"]] = scaler.fit_transform(\n",
        "    df[[\"latitude\", \"longitude\", \"time_diff\", \"distance_diff\"]]\n",
        ")\n",
        "\n",
        "X = df[[\"latitude\", \"longitude\", \"time_diff\", \"distance_diff\"]]\n",
        "\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=10).fit(X)\n",
        "df[\"dbscan_cluster\"] = dbscan.labels_\n",
        "\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
        "df[\"lof_score\"] = lof.fit_predict(X)\n",
        "\n",
        "\n",
        "df[\"stalker_label\"] = np.where((df[\"dbscan_cluster\"] == -1) | (df[\"lof_score\"] == -1), 1, 0)\n",
        "\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X, df[\"stalker_label\"])\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "def create_sequences(data, seq_length=10):\n",
        "    sequences, labels = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        sequences.append(data[i: i + seq_length])\n",
        "        labels.append(data[i + seq_length])\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "seq_length = 10\n",
        "X_seq, y_seq = create_sequences(X.values, seq_length)\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    LSTM(50, activation=\"relu\", return_sequences=True, input_shape=(seq_length, X.shape[1])),\n",
        "    LSTM(50, activation=\"relu\"),\n",
        "    Dense(X.shape[1])\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "lstm_model.fit(X_seq, y_seq, epochs=10, batch_size=32, verbose=1, validation_split=0.2)\n",
        "\n",
        "\n",
        "y_pred = lstm_model.predict(X_seq)\n",
        "mse = np.mean(np.square(y_seq - y_pred))\n",
        "print(f\"Model MSE: {mse}\")\n",
        "\n",
        "y_proba = rf_model.predict_proba(X)[:, 1]\n",
        "threshold = 0.7\n",
        "df[\"final_prediction\"] = (y_proba >= threshold).astype(int)\n",
        "\n",
        "precision = precision_score(df[\"stalker_label\"], df[\"final_prediction\"])\n",
        "recall = recall_score(df[\"stalker_label\"], df[\"final_prediction\"])\n",
        "f1 = f1_score(df[\"stalker_label\"], df[\"final_prediction\"])\n",
        "conf_matrix = confusion_matrix(df[\"stalker_label\"], df[\"final_prediction\"])\n",
        "roc_auc = roc_auc_score(df[\"stalker_label\"], y_proba)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "\n",
        "def check_stalker(lat, lon, time_diff, distance_diff):\n",
        "    user_data = scaler.transform([[lat, lon, time_diff, distance_diff]])\n",
        "    prediction = rf_model.predict(user_data)[0]\n",
        "    if prediction == 1:\n",
        "        print(\"⚠️ Warning: This location shows unusual movement patterns!\")\n",
        "    else:\n",
        "        print(\"✅ No suspicious activity detected.\")\n",
        "\n",
        "# Accepting user input\n",
        "user_lat = float(input(\"Enter latitude: \"))\n",
        "user_lon = float(input(\"Enter longitude: \"))\n",
        "user_time_diff = float(input(\"Enter time interval in seconds: \"))\n",
        "user_distance_diff = float(input(\"Enter distance covered in meters: \"))\n",
        "\n",
        "check_stalker(user_lat, user_lon, user_time_diff, user_distance_diff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRyYxu4Wq2Fn",
        "outputId": "3d937356-e05e-427f-ed89-2df28fd97657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-758156703124>:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df[\"distance_diff\"] = df.groupby(\"user_id\").apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 1.0039 - val_loss: 0.9736\n",
            "Epoch 2/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.9629 - val_loss: 0.9678\n",
            "Epoch 3/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.9601 - val_loss: 0.9607\n",
            "Epoch 4/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.9534 - val_loss: 0.9545\n",
            "Epoch 5/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.9432 - val_loss: 0.9500\n",
            "Epoch 6/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.9417 - val_loss: 0.9502\n",
            "Epoch 7/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.9364 - val_loss: 0.9495\n",
            "Epoch 8/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 0.9366 - val_loss: 0.9484\n",
            "Epoch 9/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.9464 - val_loss: 0.9503\n",
            "Epoch 10/10\n",
            "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.9364 - val_loss: 0.9523\n",
            "\u001b[1m1070/1070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
            "Model MSE: 0.9350211625595635\n",
            "Precision: 1.0\n",
            "Recall: 0.9939138576779026\n",
            "F1 Score: 0.9969476402911481\n",
            "Confusion Matrix:\n",
            " [[32114     0]\n",
            " [   13  2123]]\n",
            "ROC AUC Score: 1.0\n",
            "Enter latitude: 12.59\n",
            "Enter longitude: 77.43\n",
            "Enter time interval in seconds: 60\n",
            "Enter distance covered in meters: 40\n",
            "⚠️ Warning: This location shows unusual movement patterns!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wX0DW6jWskuz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}